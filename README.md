###  Text Classification to Detect AI Generated Text

The repository applies different AI models to  detect AI generated text from the submissions made by students.

 Our goal is to identify the model that can clearly distinguish if student has written the text or AI has generated the text. 

**Author** 
Indira Jyothi Yellapragada

#### Executive summary

**Project overview and goals:** The goal of this project is to identify more effective ways for detecting AI generated text from student submissions and evaluating the best model for detecting AI generated text. We will be training and tuning few binary text classification models to accurately classify texts as AI generated or not. Models will be able to predict, from future/unseen text, whether the text is original content of student or AI generated. We will then evaluate and compare the  models' performances to identify the best one. Lastly, we will draw insights from our analyses and recommmend areas to research and courses to undertake for future work in detecting AI generated text.  

#### Rationale
This is an important to encourage Students to submit their original work. Instructors have lot of extra work these days to identify students who plagiarize. This model should save time for the teachers.
#### Research Question

The question this project aims to answer is what is the best classification model for detecting if the submissions were made by students or LLM(Large Language Models such as ChatGPT)  has generated text.

#### Data Sources
The dataset used is from [Kaggle Competition](https://www.kaggle.com/code/alexia/kerasnlp-starter-notebook-llm-detect-ai-generate) .


Dataset Used is found [here](data/) 

#### Methodology

The repository performs an analysis of text, aiming to identify a NLP Classification model that can detect AI generated text. 
Here's a breakdown of the key steps and insights:
##### Exploratory Data Analysis (EDA):
**Data Inspection**: The code starts by examining the number of values for “generated” column in the essays_df dataset. Observed that  the data contains only text generated by students. So, added records from dataset generated by Derick. \
**Visualizations**: Scatter plots and histograms are generated to visualize the relationship between various features (source, prompt) and the target variable (‘generated’). These visualizations help understand the correlation between the features.\
**Data Distribution**: Examining the value counts for text_length to understand the distribution of text_length.
##### Data Preparation: 
**Feature Engineering**: An ‘text length” column is created to check if that helps in the classification.\
**Data Cleaning**: Columns with identifiers (prompt_id, text_id) are removed as they don't contribute to text.\
**Data Type Conversion**: All text columns are converted to string type.
##### Modeling:
**Train-Test Split**: Data is split into 80% training and 20% testing sets.\
**Normalization**: Perform CountVectorization to remove stopwords of English and all “non-english” words from the text and count the word in the text. Apply Logistic Regression with such data \
**Feature Extraction**:Performed TFIDF to extract features.TFIDF  stands for Term Frequency-Inverse Document Frequency, is a numerical statistic that reflects the importance of a word in a document relative to a collection of documents. 
**Baseline Classifier**: Applied Dummy Classifier on data extracted with TFIDF Vectorizer and got 73.3% of accuracy_score.\
**Logistic Regression**: 
Logistic regression predicts the probability of text being AI generated. 

A Logistic regression model is trained with TFIDF Vectorized data and received accuracy_Score of 99.7%.\
A Logistic regression model is trained with Count Vectorized data and received accuracy_Score of 86.8%.\
**Decision Tree**: Decision Tree maps all potential possibilities of text being AI generated. Decision Tree model is trained with TFIDF and received accuracy_score of 97.04%.\
**K Nearest Neighbors**: This model  works by identifying the k most similar data points (neighbors) to a new data point and using their labels or values to predict the new point's class or value. K Nearest Neighbors model is trained with TFIDF and received accuracy_score of 99.9%.\
**Support Vector Classifier(SVC)**: SVC finds the best-fitting line (or hyperplane in higher dimensions) that separates different data classes, maximizing the distance between the line and the closest data points of each class. This distance is called the margin, and SVMs aim to find the hyperplane that maximizes this margin. SVM model is trained with TFIDF and received accuracy_score of 99.8%.\
**Naive Bayes**:This model is based on Bayes theorem with assumption that features are independent. This model calculates probability of text being AI generated. This model is trained with TFIDF data and received accuracy_score of  100%.\
**LatentDirichlet Allocation(LDA)**:This model aims to discover the latent topics (hidden themes) within a collection of texts.  Applied LDA embedding and applied Logistic Regression on the data and achieved accuracy _score of 97.6%\
**NMF** : Applied NMF embedding and applied Logistic Regression on the data and achieved accuracy _score of 86.9%
#### Results
Fine tuned SVC model with different parameters using Grid SearchCV. 
Best parameters of SVC was C(regularization parameter)=10 and svc_probability=True.
Fine tuned Naive Bayes model with different parameters using Grid SearchCV. 
Best parameters of Naive bayes was alpha=1 

Evaluated all these models on the basis of metrics such as F1Score, Precision, Recall and Accuracy Score. Also checked the Confusion Matrix to identify the number of TruePositives, TrueNegatives,False Positive and false Negatives. 
![Screenshot 2025-05-20 at 6 38 13 PM](https://github.com/user-attachments/assets/4a8c5f24-737a-4952-8b3a-7430db8fc85f)
Based on all of these , Naive Bayes has outperformed all the other 
models.

#### Next steps
We can explore more by identifying text specific to subject and list of words that appear only in AI generated text and those that appear only in original text.

#### Outline of project

- [Data](data/)
- [Link to notebook](prompts.ipynb)


##### Contact and Further Information


Indira Jyothi Yellapragada
[Linked In](https://www.linkedin.com/in/indirajyothi-yellapragada/)
Email: indirajyothi.yellapragada@gmail.com


